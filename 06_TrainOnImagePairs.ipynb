{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Image Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have spent a lot of time trying to create and discover images pairs within our dataset. Now it's time to see whether or not we can actually extract any training signal from these pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import open_image, pil2tensor\n",
    "from fastai.vision import get_image_files, get_transforms, unet_learner, imagenet_stats\n",
    "from fastai.vision import models, SegmentationItemList, ResizeMethod, DatasetType\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from src.utils import convert_mask_to_rle, convert_masks_to_rle\n",
    "from src.utils import override_open_mask, get_training_image_size, multiclass_dice, BCEDiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('data')\n",
    "TRAIN = DATA/\"train.csv\"\n",
    "TEST = DATA/\"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN)\n",
    "test = pd.read_csv(TEST)\n",
    "\n",
    "train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test['label'] = test['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "test['im_id'] = test['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "unique_images = train.iloc[::4, :]\n",
    "unique_test_images = test.iloc[::4, :]\n",
    "\n",
    "test['EncodedPixels'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "TRAIN_FOLDER = DATA/'train_images_350x525'\n",
    "TEST_FOLDER = DATA/'test_images_350x525'\n",
    "train_images = get_image_files(TRAIN_FOLDER)\n",
    "test_images = get_image_files(TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_pairs = np.load(DATA/'train_train_pairs.npy', allow_pickle=True)[()]\n",
    "train_test_pairs = np.load(DATA/'train_test_pairs.npy', allow_pickle=True)[()]\n",
    "test_test_pairs = np.load(DATA/'test_test_pairs.npy', allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train to train pairs: 1770\n",
      "train to test pairs: 1202\n",
      "test to test pairs: 798\n"
     ]
    }
   ],
   "source": [
    "print(\"train to train pairs:\", len(train_train_pairs))\n",
    "print(\"train to test pairs:\", len(train_test_pairs))\n",
    "print(\"test to test pairs:\", len(test_test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainID_testID_pairs = {}\n",
    "trainID_trainID_pairs = {}\n",
    "\n",
    "for trainIdx1, trainIdx2 in train_train_pairs.items():\n",
    "    \n",
    "    train_id1 = train_images[trainIdx1].name\n",
    "    train_id2 = train_images[trainIdx2].name\n",
    "    \n",
    "    trainID_trainID_pairs[train_id1] = train_id2\n",
    "\n",
    "for trainIdx, testIdx in train_test_pairs.items():\n",
    "    \n",
    "    train_id = train_images[trainIdx].name\n",
    "    test_id = test_images[testIdx].name\n",
    "    \n",
    "    trainID_testID_pairs[train_id] = test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is generate a baseline for performance so we can gauge whether or not we're improving things. We'll train a model against the entire training set, but only test it against the `1202` images found within `train_test_pairs`.\n",
    "\n",
    "In the future we're hoping that using pair information will help boost our score on these test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure we open our 4D masks properly\n",
    "override_open_mask()\n",
    "\n",
    "def get_y_fn(x):\n",
    "    # Given a path to a training image, build the corresponding mask path\n",
    "    split = x.split('/')\n",
    "    newPath = DATA/(\"train_images_annots\" + SUFFIX)/split[-1].replace('.jpg','.png')\n",
    "    return newPath\n",
    "\n",
    "size = (350,525)\n",
    "training_image_size = get_training_image_size(size)     #UNet requires that inputs are multiples of 32\n",
    "#If we want to train on smaller images, we can add their suffix here\n",
    "SUFFIX = \"_\" + str(size[0]) + \"x\" + str(size[1])        #eg. _350x525\n",
    "batch_size=8\n",
    "codes = np.array(['Fish', 'Flower', 'Gravel', 'Sugar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create test set consisting of images for which we have a pair in train\n",
    "paired_test_images = unique_test_images.loc[unique_test_images['im_id'].isin(list(trainID_testID_pairs.values()))].reset_index()\n",
    "\n",
    "len(paired_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (SegmentationItemList.from_df(unique_images, DATA/('train_images'+str(SUFFIX)), cols='im_id')\n",
    "       .split_none()\n",
    "    .label_from_func(get_y_fn, classes=codes))\n",
    "\n",
    "test_src = SegmentationItemList.from_df(paired_test_images, DATA / ('test_images' + str(SUFFIX)), cols='im_id')\n",
    "\n",
    "transforms = get_transforms()\n",
    "data = (src.transform(get_transforms(), tfm_y=True, size=training_image_size, resize_method=ResizeMethod.PAD, padding_mode=\"zeros\")\n",
    "        .add_test(test_src, tfm_y=False)\n",
    "        .databunch(bs=batch_size)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "learn = unet_learner(data, models.xresnet18, pretrained=False, metrics=[multiclass_dice], loss_func=BCEDiceLoss(), model_dir=DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>multiclass_dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.949255</td>\n",
       "      <td>#na#</td>\n",
       "      <td>06:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.896205</td>\n",
       "      <td>#na#</td>\n",
       "      <td>06:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.909518</td>\n",
       "      <td>#na#</td>\n",
       "      <td>06:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.883361</td>\n",
       "      <td>#na#</td>\n",
       "      <td>06:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.913122</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.884484</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.883727</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.861732</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.846374</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.845968</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.862371</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.855961</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.821005</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.808423</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.822237</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.801002</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.794661</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.810773</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.801369</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.780719</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.777608</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.769569</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.776156</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.771473</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.761266</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.759397</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.754663</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.751639</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.728299</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.717284</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.710513</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.713241</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.716363</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.696879</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.686643</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.664187</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.668316</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.651252</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.641381</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.642550</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.617241</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.622984</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.609862</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.591435</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.586948</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.584704</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.559476</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.569416</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.562321</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.550858</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.540445</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.556795</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.545844</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.548835</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.537402</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.542725</td>\n",
       "      <td>#na#</td>\n",
       "      <td>05:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "learn.fit_one_cycle(60, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: It looks like these are logits. Max: tensor(17.5079)\n"
     ]
    }
   ],
   "source": [
    "# Get test predictions\n",
    "test_preds, _ = learn.get_preds(DatasetType.Test)\n",
    "if test_preds.max() > 1:\n",
    "    # If we use custom loss functions, we have to apply the activation ourselves\n",
    "    print(\"TEST: It looks like these are logits. Max:\", test_preds.max())\n",
    "    test_preds = torch.sigmoid(test_preds)\n",
    "\n",
    "test_preds = test_preds.numpy()\n",
    "test_preds = test_preds[:, :, :350, :525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1202it [00:24, 49.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert masks to RLE\n",
    "threshold = 0.5\n",
    "min_size = 10000\n",
    "for i, row in tqdm(paired_test_images.iterrows()):\n",
    "    saved_pred = test_preds[i]\n",
    "\n",
    "    fish_rle = convert_mask_to_rle(saved_pred[0], threshold, min_size)\n",
    "    flower_rle = convert_mask_to_rle(saved_pred[1], threshold, min_size)\n",
    "    gravel_rle = convert_mask_to_rle(saved_pred[2], threshold, min_size)\n",
    "    sugar_rle = convert_mask_to_rle(saved_pred[3], threshold, min_size)\n",
    "\n",
    "    # Save in dataframe\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Fish\", 'EncodedPixels'] = fish_rle\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Flower\", 'EncodedPixels'] = flower_rle\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Gravel\", 'EncodedPixels'] = gravel_rle\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Sugar\", 'EncodedPixels'] = sugar_rle\n",
    "\n",
    "submission = test.drop(columns=['label', 'im_id'])\n",
    "submission.to_csv(\"submissions/pair_test_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear submission\n",
    "test['EncodedPixels'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_train_images = unique_images.loc[unique_images['im_id'].isin(list(trainID_trainID_pairs.keys()))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_mask = [trainID_trainID_pairs[k] for k in paired_train_images['im_id']]\n",
    "paired_train_images['pair_im_id'] = pair_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>label</th>\n",
       "      <th>im_id</th>\n",
       "      <th>pair_im_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>002be4f.jpg_Fish</td>\n",
       "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>2688104.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0031ae9.jpg_Fish</td>\n",
       "      <td>3510 690 4910 690 6310 690 7710 690 9110 690 1...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>0031ae9.jpg</td>\n",
       "      <td>da0d544.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0035239.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fish</td>\n",
       "      <td>0035239.jpg</td>\n",
       "      <td>61aa8dc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>008a5ff.jpg_Fish</td>\n",
       "      <td>1038475 213 1039875 213 1041275 213 1042675 21...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>008a5ff.jpg</td>\n",
       "      <td>269a0ef.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>009e2f3.jpg_Fish</td>\n",
       "      <td>65812 93 65906 4 65911 10 67212 96 67309 5 673...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>009e2f3.jpg</td>\n",
       "      <td>dd2de1a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>22144</td>\n",
       "      <td>ffbf254.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fish</td>\n",
       "      <td>ffbf254.jpg</td>\n",
       "      <td>bc3f6f9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>22148</td>\n",
       "      <td>ffc31af.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fish</td>\n",
       "      <td>ffc31af.jpg</td>\n",
       "      <td>4f3407b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>22152</td>\n",
       "      <td>ffca427.jpg_Fish</td>\n",
       "      <td>613784 292 614079 2 615184 294 615480 1 616584...</td>\n",
       "      <td>Fish</td>\n",
       "      <td>ffca427.jpg</td>\n",
       "      <td>9901417.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>22168</td>\n",
       "      <td>ffd11b6.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fish</td>\n",
       "      <td>ffd11b6.jpg</td>\n",
       "      <td>523a7eb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>22172</td>\n",
       "      <td>ffd3dfb.jpg_Fish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fish</td>\n",
       "      <td>ffd3dfb.jpg</td>\n",
       "      <td>dfb4e2b.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1770 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       Image_Label  \\\n",
       "0         4  002be4f.jpg_Fish   \n",
       "1         8  0031ae9.jpg_Fish   \n",
       "2        12  0035239.jpg_Fish   \n",
       "3        36  008a5ff.jpg_Fish   \n",
       "4        48  009e2f3.jpg_Fish   \n",
       "...     ...               ...   \n",
       "1765  22144  ffbf254.jpg_Fish   \n",
       "1766  22148  ffc31af.jpg_Fish   \n",
       "1767  22152  ffca427.jpg_Fish   \n",
       "1768  22168  ffd11b6.jpg_Fish   \n",
       "1769  22172  ffd3dfb.jpg_Fish   \n",
       "\n",
       "                                          EncodedPixels label        im_id  \\\n",
       "0     233813 878 235213 878 236613 878 238010 881 23...  Fish  002be4f.jpg   \n",
       "1     3510 690 4910 690 6310 690 7710 690 9110 690 1...  Fish  0031ae9.jpg   \n",
       "2                                                   NaN  Fish  0035239.jpg   \n",
       "3     1038475 213 1039875 213 1041275 213 1042675 21...  Fish  008a5ff.jpg   \n",
       "4     65812 93 65906 4 65911 10 67212 96 67309 5 673...  Fish  009e2f3.jpg   \n",
       "...                                                 ...   ...          ...   \n",
       "1765                                                NaN  Fish  ffbf254.jpg   \n",
       "1766                                                NaN  Fish  ffc31af.jpg   \n",
       "1767  613784 292 614079 2 615184 294 615480 1 616584...  Fish  ffca427.jpg   \n",
       "1768                                                NaN  Fish  ffd11b6.jpg   \n",
       "1769                                                NaN  Fish  ffd3dfb.jpg   \n",
       "\n",
       "       pair_im_id  \n",
       "0     2688104.jpg  \n",
       "1     da0d544.jpg  \n",
       "2     61aa8dc.jpg  \n",
       "3     269a0ef.jpg  \n",
       "4     dd2de1a.jpg  \n",
       "...           ...  \n",
       "1765  bc3f6f9.jpg  \n",
       "1766  4f3407b.jpg  \n",
       "1767  9901417.jpg  \n",
       "1768  523a7eb.jpg  \n",
       "1769  dfb4e2b.jpg  \n",
       "\n",
       "[1770 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from test images to corresponding train images\n",
    "testID_trainID_pairs = inv_map = {v: k for k, v in trainID_testID_pairs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_open(self, fn):\n",
    "    \"\"\"\n",
    "    Opens an image and it's corresponding pair's mask. \n",
    "    Concatenates them together along the first (channel) dimension and returns them as a fastai Image\n",
    "    \"\"\"\n",
    "\n",
    "    img = Image.open(fn).convert(self.convert_mode)\n",
    "    if self.after_open: \n",
    "        img = self.after_open(img)\n",
    "        \n",
    "    img = pil2tensor(img, np.float32)\n",
    "    img.div_(255)\n",
    "    \n",
    "    # Open mask for image pair\n",
    "    im_id = fn.split('/')[-1]\n",
    "    \n",
    "    # HACK: We have two different lookups:\n",
    "    # One maps pairs from train to train\n",
    "    # One maps pairs from test to train\n",
    "    # We're assuming that if we can't find the pair in the train-to-train lookup, it must exist in the other one\n",
    "    pair_id = None\n",
    "    if 'train_images' in fn and im_id in trainID_trainID_pairs:\n",
    "        pair_id = trainID_trainID_pairs[im_id]\n",
    "    elif 'test_images' in fn:\n",
    "        pair_id = testID_trainID_pairs[im_id]\n",
    "\n",
    "    if pair_id is not None:\n",
    "        mask_id = pair_id.replace('.jpg', '.png')\n",
    "\n",
    "        mask_path = DATA/'train_images_annots_350x525'/mask_id\n",
    "        mask = Image.open(mask_path).convert('RGBA')\n",
    "        mask = pil2tensor(mask, np.float32)\n",
    "    else:\n",
    "        mask = torch.zeros((4, img.shape[1], img.shape[2]))\n",
    "    \n",
    "    x = torch.cat([img, mask], dim=0)\n",
    "\n",
    "    hybrid_image = fastai.vision.Image(x)\n",
    "\n",
    "    return hybrid_image\n",
    "\n",
    "SegmentationItemList.open = custom_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before tensor(0.2763, grad_fn=<StdBackward0>)\n",
      "After tensor(0.1782, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src = (SegmentationItemList.from_df(unique_images, DATA/('train_images'+str(SUFFIX)), cols='im_id')\n",
    "       .split_none()\n",
    "    .label_from_func(get_y_fn, classes=codes))\n",
    "\n",
    "test_src = SegmentationItemList.from_df(paired_test_images, DATA / ('test_images' + str(SUFFIX)), cols='im_id')\n",
    "\n",
    "transforms = get_transforms()\n",
    "data = (src.transform(get_transforms(), tfm_y=True, size=training_image_size, resize_method=ResizeMethod.PAD, padding_mode=\"zeros\")\n",
    "        .add_test(test_src, tfm_y=False)\n",
    "        .databunch(bs=batch_size))\n",
    "\n",
    "def custom_resnet(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Create custom ResNet that accepts 7-channel inputs\n",
    "    \"\"\"\n",
    "    model = models.xresnet18(pretrained, **kwargs)\n",
    "    print(\"Before\", model[0][0].weight.std())\n",
    "    model[0][0] = torch.nn.Conv2d(7, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    torch.nn.init.kaiming_normal_(model[0][0].weight)\n",
    "    print(\"After\", model[0][0].weight.std())\n",
    "\n",
    "    return model\n",
    "\n",
    "learn = unet_learner(data, custom_resnet, pretrained=False, metrics=[multiclass_dice], loss_func=BCEDiceLoss(), model_dir=DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>multiclass_dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.964705</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.932413</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.913778</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.918253</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.907770</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.898980</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.883485</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.874966</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.849967</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.853980</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.846375</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.844347</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.831013</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.850216</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.819607</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.814789</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.801770</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.822092</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.814936</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.788747</td>\n",
       "      <td>#na#</td>\n",
       "      <td>08:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.787675</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.767835</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.754963</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.764858</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.771236</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.777897</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.743551</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.752303</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.744590</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.734462</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.735776</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.721981</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.715760</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.695089</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.696535</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.687623</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.678794</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.668422</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.663484</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.656204</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.653861</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.659735</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.621475</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.627092</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.618627</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.620884</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.606128</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.586013</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.592693</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.570722</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.588690</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.588787</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.570901</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.579207</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.589451</td>\n",
       "      <td>#na#</td>\n",
       "      <td>07:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "learn.fit_one_cycle(60, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: It looks like these are logits. Max: tensor(12.2118)\n"
     ]
    }
   ],
   "source": [
    "# Get test predictions\n",
    "test_preds, _ = learn.get_preds(DatasetType.Test)\n",
    "if test_preds.max() > 1:\n",
    "    # If we use custom loss functions, we have to apply the activation ourselves\n",
    "    print(\"TEST: It looks like these are logits. Max:\", test_preds.max())\n",
    "    test_preds = torch.sigmoid(test_preds)\n",
    "\n",
    "test_preds = test_preds.numpy()\n",
    "test_preds = test_preds[:, :, :350, :525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1202it [00:25, 47.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert masks to RLE\n",
    "threshold = 0.5\n",
    "min_size = 10000\n",
    "for i, row in tqdm(paired_test_images.iterrows()):\n",
    "    saved_pred = test_preds[i]\n",
    "\n",
    "    fish_rle = convert_mask_to_rle(saved_pred[0], threshold, min_size)\n",
    "    flower_rle = convert_mask_to_rle(saved_pred[1], threshold, min_size)\n",
    "    gravel_rle = convert_mask_to_rle(saved_pred[2], threshold, min_size)\n",
    "    sugar_rle = convert_mask_to_rle(saved_pred[3], threshold, min_size)\n",
    "\n",
    "    # Save in dataframe\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Fish\", 'EncodedPixels'] = fish_rle\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Flower\", 'EncodedPixels'] = flower_rle\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Gravel\", 'EncodedPixels'] = gravel_rle\n",
    "    test.loc[test['Image_Label'] == row['im_id'] + \"_Sugar\", 'EncodedPixels'] = sugar_rle\n",
    "\n",
    "submission = test.drop(columns=['label', 'im_id'])\n",
    "submission.to_csv(\"submissions/trained_with_pair_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Labels and Paired Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other approach that may work would be to train with both the corresponding label and paired image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear submission\n",
    "test['EncodedPixels'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_train_images = unique_images.loc[unique_images['im_id'].isin(list(trainID_trainID_pairs.keys()))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_mask = [trainID_trainID_pairs[k] for k in paired_train_images['im_id']]\n",
    "paired_train_images['pair_im_id'] = pair_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from test images to corresponding train images\n",
    "testID_trainID_pairs = inv_map = {v: k for k, v in trainID_testID_pairs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_open(self, fn):\n",
    "    \"\"\"\n",
    "    Opens an image and it's corresponding pair's mask. \n",
    "    Concatenates them together along the first (channel) dimension and returns them as a fastai Image\n",
    "    \"\"\"\n",
    "\n",
    "    img = Image.open(fn).convert(self.convert_mode)\n",
    "    if self.after_open: \n",
    "        img = self.after_open(img)\n",
    "        \n",
    "    img = pil2tensor(img, np.float32)\n",
    "    img.div_(255)\n",
    "    \n",
    "    # Open mask for image pair\n",
    "    im_id = fn.split('/')[-1]\n",
    "    \n",
    "    # HACK: We have two different lookups:\n",
    "    # One maps pairs from train to train\n",
    "    # One maps pairs from test to train\n",
    "    # We're assuming that if we can't find the pair in the train-to-train lookup, it must exist in the other one\n",
    "    if im_id in trainID_trainID_pairs:\n",
    "        pair_id = trainID_trainID_pairs[im_id]\n",
    "    else:\n",
    "        pair_id = testID_trainID_pairs[im_id]\n",
    "        \n",
    "    mask_id = pair_id.replace('.jpg', '.png')\n",
    "\n",
    "    mask_path = DATA/'train_images_annots_350x525'/mask_id\n",
    "    mask = Image.open(mask_path).convert('RGBA')\n",
    "    mask = pil2tensor(mask, np.float32)\n",
    "    \n",
    "    #open the paired image\n",
    "    img2 = Image.open(DATA/'train_images_350x525'/pairId).convert(self.convert_mode)\n",
    "    if self.after_open: \n",
    "        img2 = self.after_open(img2)\n",
    "        \n",
    "    img2 = pil2tensor(img2, np.float32)\n",
    "    img2.div_(255)\n",
    "    \n",
    "    \n",
    "    x = torch.cat([img, mask, img2], dim=0)\n",
    "\n",
    "    hybrid_image = fastai.vision.Image(x)\n",
    "\n",
    "    return hybrid_image\n",
    "\n",
    "SegmentationItemList.open = custom_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (SegmentationItemList.from_df(paired_train_images, DATA/('train_images'+str(SUFFIX)), cols='im_id')\n",
    "       .split_none()\n",
    "    .label_from_func(get_y_fn, classes=codes))\n",
    "\n",
    "test_src = SegmentationItemList.from_df(paired_test_images, DATA / ('test_images' + str(SUFFIX)), cols='im_id')\n",
    "\n",
    "transforms = get_transforms()\n",
    "data = (src.transform(get_transforms(), tfm_y=True, size=training_image_size, resize_method=ResizeMethod.PAD, padding_mode=\"zeros\")\n",
    "        .add_test(test_src, tfm_y=False)\n",
    "        .databunch(bs=batch_size))\n",
    "\n",
    "def custom_resnet(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Create custom ResNet that accepts 10-channel inputs\n",
    "    \"\"\"\n",
    "    model = models.xresnet18(pretrained, **kwargs)\n",
    "    print(\"Before\", model[0][0].weight.std())\n",
    "    model[0][0] = torch.nn.Conv2d(10, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    torch.nn.init.kaiming_normal_(model[0][0].weight)\n",
    "    print(\"After\", model[0][0].weight.std())\n",
    "\n",
    "    return model\n",
    "\n",
    "learn = unet_learner(data, custom_resnet, pretrained=False, metrics=[multiclass_dice], loss_func=BCEDiceLoss(), model_dir=DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "learn.fit_one_cycle(10, 1e-3)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(60, slice(1e-6, 1e-3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
