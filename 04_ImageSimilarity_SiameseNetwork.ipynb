{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from fastai.vision import get_image_files\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for removing the FC head of a network\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"data\")\n",
    "train = pd.read_csv(data/'image_similarity_train.csv')\n",
    "valid = pd.read_csv(data/'image_similarity_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Based on: https://github.com/adambielski/siamese-triplet/blob/0c719f9e8f59fa386e8c59d10b2ddde9fac46276/datasets.py#L8\n",
    "    \n",
    "    Train: For each sample creates randomly a positive or a negative pair\n",
    "    Test: Creates fixed pairs for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.train = self.dataset['train']\n",
    "        self.transform = self.dataset['transform']\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = self.dataset['labels']\n",
    "            self.train_data = self.dataset['data']\n",
    "            self.labels_set = set(self.train_labels)\n",
    "            self.label_to_indices = {label: np.where(self.train_labels == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "        else:\n",
    "            # generate fixed pairs for testing\n",
    "            self.test_labels = self.dataset['labels']\n",
    "            self.test_data = self.dataset['data']\n",
    "            self.labels_set = set(self.test_labels)\n",
    "            self.label_to_indices = {label: np.where(self.test_labels == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            positive_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[self.test_labels[i]]),\n",
    "                               1]\n",
    "                              for i in range(0, len(self.test_data), 2)]\n",
    "\n",
    "            negative_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[\n",
    "                                                       np.random.choice(\n",
    "                                                           list(self.labels_set - set([self.test_labels[i]]))\n",
    "                                                       )\n",
    "                                                   ]),\n",
    "                               0]\n",
    "                              for i in range(1, len(self.test_data), 2)]\n",
    "            self.test_pairs = positive_pairs + negative_pairs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            target = np.random.randint(0, 2)\n",
    "            img1, label1 = Image.open(self.train_data[index]), self.train_labels[index]\n",
    "            if target == 1:\n",
    "                siamese_index = index\n",
    "                while siamese_index == index:\n",
    "                    siamese_index = np.random.choice(self.label_to_indices[label1])\n",
    "            else:\n",
    "                siamese_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "                siamese_index = np.random.choice(self.label_to_indices[siamese_label])\n",
    "            img2 = Image.open(self.train_data[siamese_index])\n",
    "        else:\n",
    "            img1 = Image.open(self.test_data[self.test_pairs[index][0]])\n",
    "            img2 = Image.open(self.test_data[self.test_pairs[index][1]])\n",
    "            target = self.test_pairs[index][2]\n",
    "\n",
    "        #img1 = Image.fromarray(img1.numpy(), mode='L')\n",
    "        #img2 = Image.fromarray(img2.numpy(), mode='L')\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return (img1, img2), target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "        train_data = {\n",
    "    'train': True,\n",
    "    'transform': transforms.Compose([transforms.ToTensor()]),\n",
    "    'df': train,\n",
    "    'labels': np.array(train['Label']),\n",
    "    'data': np.array(train['Path'])\n",
    "}\n",
    "\n",
    "valid_data = {\n",
    "    'train': False,\n",
    "    'transform': transforms.Compose([transforms.ToTensor()]),\n",
    "    'df': valid,\n",
    "    'labels': np.array(valid['Label']),\n",
    "    'data': np.array(valid['Path'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'train': True,\n",
    "    'transform': transforms.Compose([transforms.ToTensor()]),\n",
    "    'df': train,\n",
    "    'labels': np.array(train['Label']),\n",
    "    'data': np.array(train['Path'])\n",
    "}\n",
    "\n",
    "valid_data = {\n",
    "    'train': False,\n",
    "    'transform': transforms.Compose([transforms.ToTensor()]),\n",
    "    'df': valid,\n",
    "    'labels': np.array(valid['Label']),\n",
    "    'data': np.array(valid['Path'])\n",
    "}\n",
    "\n",
    "train_ds = SiameseDataset(train_data)\n",
    "test_ds = SiameseDataset(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "siamese_train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "siamese_test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a Siamese Network. It takes two images and returns the feature vector for each one by running it through an embedding network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output1 = self.embedding_net(x1)\n",
    "        output2 = self.embedding_net(x2)\n",
    "        return output1, output2\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss\n",
    "    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, output1, output2, target, size_average=True):\n",
    "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\n",
    "        losses = 0.5 * (target.float() * distances +\n",
    "                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must define the training loop for our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[],\n",
    "        start_epoch=0):\n",
    "    \"\"\"\n",
    "    Loaders, model, loss function and metrics should work together for a given task,\n",
    "    i.e. The model should be able to process data output of loaders,\n",
    "    loss function should process target output of loaders and outputs from the model\n",
    "    Examples: Classification: batch loader, classification model, NLL loss, accuracy metric\n",
    "    Siamese network: Siamese loader, siamese model, contrastive loss\n",
    "    Online triplet learning: batch loader, embedding model, online triplet loss\n",
    "    \"\"\"\n",
    "    for epoch in range(0, start_epoch):\n",
    "        scheduler.step()\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        scheduler.step()\n",
    "\n",
    "        # Train stage\n",
    "        train_loss, metrics = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)\n",
    "\n",
    "        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)\n",
    "        for metric in metrics:\n",
    "            message += '\\t{}: {}'.format(metric.name(), metric.value())\n",
    "\n",
    "        val_loss, metrics = test_epoch(val_loader, model, loss_fn, cuda, metrics)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        message += '\\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,\n",
    "                                                                                 val_loss)\n",
    "        for metric in metrics:\n",
    "            message += '\\t{}: {}'.format(metric.name(), metric.value())\n",
    "\n",
    "        print(message)\n",
    "\n",
    "\n",
    "def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    model.train()\n",
    "    losses = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target if len(target) > 0 else None\n",
    "        if not type(data) in (tuple, list):\n",
    "            data = (data,)\n",
    "        if cuda:\n",
    "            data = tuple(d.cuda() for d in data)\n",
    "            if target is not None:\n",
    "                target = target.cuda()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*data)\n",
    "\n",
    "        if type(outputs) not in (tuple, list):\n",
    "            outputs = (outputs,)\n",
    "\n",
    "        loss_inputs = outputs\n",
    "        if target is not None:\n",
    "            target = (target,)\n",
    "            loss_inputs += target\n",
    "\n",
    "        loss_outputs = loss_fn(*loss_inputs)\n",
    "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "        losses.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric(outputs, target, loss_outputs)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_idx * len(data[0]), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), np.mean(losses))\n",
    "            for metric in metrics:\n",
    "                message += '\\t{}: {}'.format(metric.name(), metric.value())\n",
    "\n",
    "            print(message)\n",
    "            losses = []\n",
    "\n",
    "    total_loss /= (batch_idx + 1)\n",
    "    return total_loss, metrics\n",
    "\n",
    "def test_epoch(val_loader, model, loss_fn, cuda, metrics):\n",
    "    with torch.no_grad():\n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            target = target if len(target) > 0 else None\n",
    "            if not type(data) in (tuple, list):\n",
    "                data = (data,)\n",
    "            if cuda:\n",
    "                data = tuple(d.cuda() for d in data)\n",
    "                if target is not None:\n",
    "                    target = target.cuda()\n",
    "\n",
    "            outputs = model(*data)\n",
    "\n",
    "            if type(outputs) not in (tuple, list):\n",
    "                outputs = (outputs,)\n",
    "            loss_inputs = outputs\n",
    "            if target is not None:\n",
    "                target = (target,)\n",
    "                loss_inputs += target\n",
    "\n",
    "            loss_outputs = loss_fn(*loss_inputs)\n",
    "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric(outputs, target, loss_outputs)\n",
    "\n",
    "    return val_loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 1.\n",
    "\n",
    "embedding_net = models.resnet18(pretrained=True)\n",
    "embedding_net.fc = Identity()\n",
    "\n",
    "model = SiameseNet(embedding_net)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "loss_fn = ContrastiveLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/25680 (0%)]\tLoss: 4443.990234\n",
      "Train: [1600/25680 (6%)]\tLoss: 30.501981\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.329544\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.140266\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.110313\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.102520\n",
      "Train: [9600/25680 (37%)]\tLoss: 0.096784\n",
      "Train: [11200/25680 (44%)]\tLoss: 0.098797\n",
      "Train: [12800/25680 (50%)]\tLoss: 0.074948\n",
      "Train: [14400/25680 (56%)]\tLoss: 0.074734\n",
      "Train: [16000/25680 (62%)]\tLoss: 0.068625\n",
      "Train: [17600/25680 (69%)]\tLoss: 0.066985\n",
      "Train: [19200/25680 (75%)]\tLoss: 0.067691\n",
      "Train: [20800/25680 (81%)]\tLoss: 0.062039\n",
      "Train: [22400/25680 (87%)]\tLoss: 0.059375\n",
      "Train: [24000/25680 (93%)]\tLoss: 0.059170\n",
      "Train: [25600/25680 (100%)]\tLoss: 0.054960\n",
      "Epoch: 1/20. Train set: Average loss: 4.7608\n",
      "Epoch: 1/20. Validation set: Average loss: 0.0308\n",
      "Train: [0/25680 (0%)]\tLoss: 0.081460\n",
      "Train: [1600/25680 (6%)]\tLoss: 0.050560\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.055105\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.050843\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.054596\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.050383\n",
      "Train: [9600/25680 (37%)]\tLoss: 0.045807\n",
      "Train: [11200/25680 (44%)]\tLoss: 0.046199\n",
      "Train: [12800/25680 (50%)]\tLoss: 0.044087\n",
      "Train: [14400/25680 (56%)]\tLoss: 0.044457\n",
      "Train: [16000/25680 (62%)]\tLoss: 0.043500\n",
      "Train: [17600/25680 (69%)]\tLoss: 0.045888\n",
      "Train: [19200/25680 (75%)]\tLoss: 0.042047\n",
      "Train: [20800/25680 (81%)]\tLoss: 0.044698\n",
      "Train: [22400/25680 (87%)]\tLoss: 0.040675\n",
      "Train: [24000/25680 (93%)]\tLoss: 0.039435\n",
      "Train: [25600/25680 (100%)]\tLoss: 0.039331\n",
      "Epoch: 2/20. Train set: Average loss: 0.0461\n",
      "Epoch: 2/20. Validation set: Average loss: 0.0231\n",
      "Train: [0/25680 (0%)]\tLoss: 0.041714\n",
      "Train: [1600/25680 (6%)]\tLoss: 0.038954\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.038060\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.037733\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.037400\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.037336\n",
      "Train: [9600/25680 (37%)]\tLoss: 0.035336\n",
      "Train: [11200/25680 (44%)]\tLoss: 0.035246\n",
      "Train: [12800/25680 (50%)]\tLoss: 0.037405\n",
      "Train: [14400/25680 (56%)]\tLoss: 0.036521\n",
      "Train: [16000/25680 (62%)]\tLoss: 0.035498\n",
      "Train: [17600/25680 (69%)]\tLoss: 0.033393\n",
      "Train: [19200/25680 (75%)]\tLoss: 0.034102\n",
      "Train: [20800/25680 (81%)]\tLoss: 0.032688\n",
      "Train: [22400/25680 (87%)]\tLoss: 0.031145\n",
      "Train: [24000/25680 (93%)]\tLoss: 0.033263\n",
      "Train: [25600/25680 (100%)]\tLoss: 0.033198\n",
      "Epoch: 3/20. Train set: Average loss: 0.0355\n",
      "Epoch: 3/20. Validation set: Average loss: 0.0186\n",
      "Train: [0/25680 (0%)]\tLoss: 0.030803\n",
      "Train: [1600/25680 (6%)]\tLoss: 0.035559\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.033133\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.031785\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.031796\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.029739\n",
      "Train: [9600/25680 (37%)]\tLoss: 0.030644\n",
      "Train: [11200/25680 (44%)]\tLoss: 0.031427\n",
      "Train: [12800/25680 (50%)]\tLoss: 0.029865\n",
      "Train: [14400/25680 (56%)]\tLoss: 0.029957\n",
      "Train: [16000/25680 (62%)]\tLoss: 0.028726\n",
      "Train: [17600/25680 (69%)]\tLoss: 0.029053\n",
      "Train: [19200/25680 (75%)]\tLoss: 0.029655\n",
      "Train: [20800/25680 (81%)]\tLoss: 0.027150\n",
      "Train: [22400/25680 (87%)]\tLoss: 0.028865\n",
      "Train: [24000/25680 (93%)]\tLoss: 0.029321\n",
      "Train: [25600/25680 (100%)]\tLoss: 0.030989\n",
      "Epoch: 4/20. Train set: Average loss: 0.0305\n",
      "Epoch: 4/20. Validation set: Average loss: 0.0177\n",
      "Train: [0/25680 (0%)]\tLoss: 0.026248\n",
      "Train: [1600/25680 (6%)]\tLoss: 0.028416\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.029779\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.026038\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.025339\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.025385\n",
      "Train: [9600/25680 (37%)]\tLoss: 0.026405\n",
      "Train: [11200/25680 (44%)]\tLoss: 0.027266\n",
      "Train: [12800/25680 (50%)]\tLoss: 0.027575\n",
      "Train: [14400/25680 (56%)]\tLoss: 0.027360\n",
      "Train: [16000/25680 (62%)]\tLoss: 0.026093\n",
      "Train: [17600/25680 (69%)]\tLoss: 0.026680\n",
      "Train: [19200/25680 (75%)]\tLoss: 0.026538\n",
      "Train: [20800/25680 (81%)]\tLoss: 0.026934\n",
      "Train: [22400/25680 (87%)]\tLoss: 0.025050\n",
      "Train: [24000/25680 (93%)]\tLoss: 0.024186\n",
      "Train: [25600/25680 (100%)]\tLoss: 0.024942\n",
      "Epoch: 5/20. Train set: Average loss: 0.0265\n",
      "Epoch: 5/20. Validation set: Average loss: 0.0131\n",
      "Train: [0/25680 (0%)]\tLoss: 0.031197\n",
      "Train: [1600/25680 (6%)]\tLoss: 0.024923\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.026839\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.025353\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.023447\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.023784\n",
      "Train: [9600/25680 (37%)]\tLoss: 0.025291\n",
      "Train: [11200/25680 (44%)]\tLoss: 0.026509\n",
      "Train: [12800/25680 (50%)]\tLoss: 0.023775\n",
      "Train: [14400/25680 (56%)]\tLoss: 0.022409\n",
      "Train: [16000/25680 (62%)]\tLoss: 0.023267\n",
      "Train: [17600/25680 (69%)]\tLoss: 0.027695\n",
      "Train: [19200/25680 (75%)]\tLoss: 0.023791\n",
      "Train: [20800/25680 (81%)]\tLoss: 0.025045\n",
      "Train: [22400/25680 (87%)]\tLoss: 0.022994\n",
      "Train: [24000/25680 (93%)]\tLoss: 0.022843\n",
      "Train: [25600/25680 (100%)]\tLoss: 0.026631\n",
      "Epoch: 6/20. Train set: Average loss: 0.0247\n",
      "Epoch: 6/20. Validation set: Average loss: 0.0147\n",
      "Train: [0/25680 (0%)]\tLoss: 0.012726\n",
      "Train: [1600/25680 (6%)]\tLoss: 0.024789\n",
      "Train: [3200/25680 (12%)]\tLoss: 0.023350\n",
      "Train: [4800/25680 (19%)]\tLoss: 0.024605\n",
      "Train: [6400/25680 (25%)]\tLoss: 0.023755\n",
      "Train: [8000/25680 (31%)]\tLoss: 0.021796\n"
     ]
    }
   ],
   "source": [
    "fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "torch.save(model.state_dict(), \"siamese_state_dict\")\n",
    "torch.save(embedding_net.state_dict(), \"embedding_state_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our model, let's use it to try to find similar images across both the training and test sets. For now we'll assume that similar images can exist across both sets or within a single set.\n",
    "\n",
    "We can start by looking at two images we know are alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = models.resnet18(pretrained=True)\n",
    "embedding_net.fc = Identity()\n",
    "embedding_net.load_state_dict(torch.load(\"embedding_state_dict\"))\n",
    "embedding_net = embedding_net.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images \n",
    "img_path1 = 'data/train_images_350x525/ee0ba55.jpg'\n",
    "img1 = Image.open(img_path1)\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path2 = 'data/test_images_350x525/5383dcf.jpg'\n",
    "img2 = Image.open(img_path2)\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_from_path(img_path):\n",
    "    #load image\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    #convert to tensor\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0).cuda()\n",
    "\n",
    "    #send through model\n",
    "    out = embedding_net(x).detach()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_paths(paths):\n",
    "    \"\"\"\n",
    "    Get all embeddings for the images in a list of paths\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for img in tqdm(paths):\n",
    "        embedding = get_embedding_from_path(img).cpu().numpy()\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    embeddings = np.array(embeddings).squeeze()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = 'data/train_images_350x525/'\n",
    "TEST_FOLDER = 'data/test_images_350x525/'\n",
    "train_images = get_image_files(TRAIN_FOLDER)\n",
    "test_images = get_image_files(TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = get_embeddings_from_paths(train_images)\n",
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = get_embeddings_from_paths(test_images)\n",
    "test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_between_embeddings(embeddings1, embeddings2):\n",
    "    \"\"\"\n",
    "    Given two sets of embeddings, calculate the distance between both\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = np.zeros((len(embeddings1), len(embeddings2)))\n",
    "    \n",
    "    for i, row in enumerate(embeddings1):\n",
    "        if i % 500 == 0:\n",
    "            print(i, '/', len(embeddings1))\n",
    "\n",
    "        row = row[np.newaxis,:]\n",
    "        distance_row = np.sqrt(np.square(row - embeddings2).sum(axis=1))\n",
    "        distance[i,:] = distance_row\n",
    "        \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_distances = get_distance_between_embeddings(train_embeddings, train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_distances = get_distance_between_embeddings(train_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "np.save(\"train_train_distances\", train_train_distances)\n",
    "np.save(\"train_test_distances\", train_test_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_distances = np.load(\"train_train_distances.npy\")\n",
    "train_test_distances = np.load(\"train_test_distances.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_pairs(distances, threshold=0.185):\n",
    "    pairs = []\n",
    "    for i, row in enumerate(distances):\n",
    "        \n",
    "        sortedIndices = np.argsort(row)\n",
    "        \n",
    "        minIndex = sortedIndices[0]\n",
    "        minVal = row[minIndex]\n",
    "        \n",
    "        secondMinIndex = sortedIndices[1]\n",
    "        secondMinVal = row[secondMinIndex]\n",
    "\n",
    "        if minVal < threshold and minVal != 0.0:\n",
    "            pairs.append((i, minIndex))\n",
    "        elif secondMinVal < threshold and secondMinVal != 0.0:\n",
    "            # If the first value is 0.0 (eg. the image itself, try the second value)\n",
    "            pairs.append((i, secondMinIndex))\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_pairs = find_similar_pairs(train_train_distances)\n",
    "train_test_pairs = find_similar_pairs(train_test_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_train_pairs[:10]:\n",
    "    print(train_images[i[0]], \"\\n\", train_images[i[1]], sep=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_train_pairs))\n",
    "print(len(train_test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 2257\n",
    "print(train_images[img_index])\n",
    "Image.open(train_images[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_index = 660\n",
    "print(test_images[test_img_index])\n",
    "Image.open(test_images[test_img_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
