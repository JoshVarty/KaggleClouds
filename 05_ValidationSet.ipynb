{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important things I've learned participating in Kaggle competitions is that [validation sets matter](https://joshvarty.com/2019/03/25/validation-sets-matter/)! Let's take a quick look at the results we've been getting so far:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [GitHub](https://github.com/JoshVarty/KaggleClouds/issues/5):\n",
    "\n",
    "| Description | n_train | NFolds | Threshold/MinSize | Valid | LB |\n",
    "| :---         |:---         |      :---:      |    :---:      |          :---: |:---: |\n",
    "| Resnet18, get_transforms() | - | 2 |  0.5/10000   | 0.446 | 0.600|\n",
    "| Resnet18, no warp, no rotate  | 4000 |2 |  0.5/10000   | 0.452  | 0.597 |\n",
    "| XResnet18, no warp, no rotate (no pretrain)  | 4000 |2 |  0.5/10000   | 0.401  | 0.588 |\n",
    "| Resnet18, get_transforms() DiceLoss  | 4000 | 2 |  0.5/10000  | 0.508 | 0.607 |\n",
    "| Resnet18, no warp, no rotate DiceLoss  | 4000 | 2 |  0.5/10000   | 0.490  | 0.600 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our validation score (`Valid`) and leaderboard score (`LB`) do not seem strongly corellated. Often we improve on our valid datset, but do worse on the LB (and vice versa).\n",
    "\n",
    "There are some possible reasons for this:\n",
    "\n",
    "- Our valid score comes from `multiclass_dice_score` which does not take into account thresholding or minimum segment size. Our LB submissions use a threshold value of `0.5` and a minimum segment size of `10,000`\n",
    "- Our train/valid set is small. We're only using 1,000 images (4,000 train items / 4 classes) and a fold size of 2.\n",
    "- Our validation datasets may come from a different distribution as compared to our test dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking a look at the images in our valid dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from fastai.vision import get_image_files\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "skf = StratifiedKFold(n_splits=NFOLDS, random_state=RANDOM_STATE)\n",
    "\n",
    "DATA = Path('data')\n",
    "TRAIN = DATA/\"train.csv\"\n",
    "TEST = DATA/\"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN)\n",
    "test = pd.read_csv(TEST)\n",
    "\n",
    "train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test['label'] = test['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "test['im_id'] = test['Image_Label'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We count how many non-NAN labels are present for each image\n",
    "# Then we create our K-Fold splits based on this\n",
    "id_mask_count = train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().\\\n",
    "reset_index().rename(columns={'index': 'img_id', 'Image_Label': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using `id_mask_count` to create our fold, it contains a count of the number of masks present for a given image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6851470.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e8b4c68.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baee301.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7b59752.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0eff39e.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        img_id  count\n",
       "0  6851470.jpg      4\n",
       "1  e8b4c68.jpg      4\n",
       "2  baee301.jpg      4\n",
       "3  7b59752.jpg      4\n",
       "4  0eff39e.jpg      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mask_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like a sensible way to split our data but we may also want to take other things into consideration. From our previous analyses we've noticed that many images across the dataset are very similar to one another. I believe we should also take this fact into account when creating our validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "TRAIN_FOLDER = DATA/'train_images_350x525'\n",
    "TEST_FOLDER = DATA/'test_images_350x525'\n",
    "train_images = get_image_files(TRAIN_FOLDER)\n",
    "test_images = get_image_files(TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_pairs = np.load(DATA/'train_train_pairs.npy', allow_pickle=True)[()]\n",
    "train_test_pairs = np.load(DATA/'train_test_pairs.npy', allow_pickle=True)[()]\n",
    "test_test_pairs = np.load(DATA/'test_test_pairs.npy', allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desired Validation Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like our validation distribution to match our test distribution. So what does our test set look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar pairs within training set\t1770\t0.3191489361702128\n",
      "Similar pairs across train-test sets\t1202\t0.2167327803822575\n",
      "Unique images\t\t\t\t2574\t0.46411828344752976\n",
      "\n",
      "Similar pairs within test set\t\t798\t0.21579232017306652\n",
      "Similar pairs across train-test sets\t1202\t0.32504056246619795\n",
      "Unique images\t\t\t\t1698\t0.4591671173607355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Similar pairs within training set\\t{}\\t{}\".format(len(train_train_pairs), len(train_train_pairs)/len(train_images)))\n",
    "print(\"Similar pairs across train-test sets\\t{}\\t{}\".format(len(train_test_pairs), len(train_test_pairs)/len(train_images)))\n",
    "print(\"Unique images\\t\\t\\t\\t{}\\t{}\".format(len(train_images)-len(train_train_pairs)-len(train_test_pairs),(len(train_images)-len(train_train_pairs)-len(train_test_pairs))/len(train_images)))\n",
    "print()\n",
    "\n",
    "print(\"Similar pairs within test set\\t\\t{}\\t{}\".format(len(test_test_pairs), len(test_test_pairs)/len(test_images)))\n",
    "print(\"Similar pairs across train-test sets\\t{}\\t{}\".format(len(train_test_pairs), len(train_test_pairs)/len(test_images)))\n",
    "print(\"Unique images\\t\\t\\t\\t{}\\t{}\".format(len(test_images)-len(test_test_pairs)-len(train_test_pairs),(len(test_images)-len(test_test_pairs)-len(train_test_pairs))/len(test_images)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want a valid dataset in which:\n",
    " - 22% of images are pairs\n",
    " - 33% of images have a corresponding pair in the validation set\n",
    " - 46% of images are \"unique\"\n",
    " \n",
    "We have 5,546 training images, so we'll take 1,000 images to form our validation dataset:\n",
    "\n",
    " - 216 images are pairs\n",
    " - 325 images have a pair in our training set\n",
    " - 459 images are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_valid_pairs = {}\n",
    "train_valid_pairs = {}\n",
    "valid_unque = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 216 images from train_train_pairs to put into valid_valid_pairs\n",
    "keys = list(train_train_pairs.keys())\n",
    "valid_valid_list = []\n",
    "i = 0\n",
    "\n",
    "while len(valid_valid_list) < 216:\n",
    "    \n",
    "    currentKey = keys[i]\n",
    "    if currentKey not in valid_valid_list and currentKey not in valid_valid_list:\n",
    "        valid_valid_list.append(currentKey)\n",
    "        valid_valid_list.append(train_train_pairs[currentKey])\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 325 images from train_train_pairs that have a corresponding pair in the training set\n",
    "keys = list(train_train_pairs.keys())\n",
    "train_valid_list = []\n",
    "i = 0\n",
    "\n",
    "while len(train_valid_list) < 325:\n",
    "    \n",
    "    currentKey = keys[i]\n",
    "    \n",
    "    if currentKey not in train_valid_list and currentKey not in valid_valid_list:\n",
    "        train_valid_list.append(currentKey)\n",
    "        \n",
    "    i = i + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 459 images that are unique \n",
    "unique_images = []\n",
    "i = 0\n",
    "\n",
    "while len(unique_images) < 459:\n",
    "    \n",
    "    if i not in valid_valid_list and i not in train_valid_list:\n",
    "        unique_images.append(i)\n",
    "        \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_list = valid_valid_list\n",
    "valid_list.extend(train_valid_list)\n",
    "valid_list.extend(unique_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_list))\n",
    "print(len(set(valid_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_im_ids = [train_images[k].name for k in valid_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our validation dataset and corresponding training dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = train[train['im_id'].isin(valid_im_ids)]\n",
    "newTrain = train[~train['im_id'].isin(valid_im_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "18184\n"
     ]
    }
   ],
   "source": [
    "print(len(valid))\n",
    "print(len(newTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.to_csv(DATA/'valid_split.csv', index=False)\n",
    "newTrain.to_csv(DATA/'train_split.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
