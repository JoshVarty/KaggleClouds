{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to train a classifier to identify similar images of clouds. To do this, we'll make use of [NASA's Worldview Snapshots API](https://worldview.earthdata.nasa.gov/?v=-163.07942357212752,-32.18685220229665,-100.20019214430877,0.016272797703347663&t=2019-02-10-T00%3A00%3A00Z&l=VIIRS_SNPP_CorrectedReflectance_TrueColor(hidden),MODIS_Aqua_CorrectedReflectance_TrueColor(hidden),MODIS_Terra_CorrectedReflectance_TrueColor,Reference_Labels(hidden),Reference_Features(hidden),Coastlines&tr=sunglint).\n",
    "\n",
    "Data is captured from two orbiting satellites: Terra and Aqua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import requests\n",
    "import random, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import date\n",
    "from dateutil.rrule import rrule, DAILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folder structure.\n",
    "if not os.path.exists('data/terra'): os.makedirs('data/terra')\n",
    "if not os.path.exists('data/aqua'): os.makedirs('data/aqua')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls to this API look like:\n",
    "```\n",
    "https://wvs.earthdata.nasa.gov/api/v1/snapshot?\n",
    "    REQUEST=GetSnapshot\n",
    "    &TIME=2019-09-24T00:00:00Z\n",
    "                BOTTOM               LEFT              TOP                 RIGHT\n",
    "    &BBOX=-26.523608349900595,-119.85108101391648,0.6927808151093444,-95.30684642147116\n",
    "    &CRS=EPSG:4326\n",
    "    &LAYERS=MODIS_Terra_CorrectedReflectance_TrueColor,Coastlines\n",
    "    &WRAP=day,x\n",
    "    &FORMAT=image/jpeg\n",
    "    &WIDTH=559\n",
    "    &HEIGHT=619\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our images come solely from the ocean, so we should select them from these regions.\n",
    "![https://i.gyazo.com/4f1f5d737bf4685c18e74c8b863cc859.png](https://i.gyazo.com/4f1f5d737bf4685c18e74c8b863cc859.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regions\n",
    "\n",
    "We need to choose fives sets of coordinates from which we'll take our snapshots.\n",
    "\n",
    "### Atlantic [1]\n",
    "\n",
    "\n",
    "- Bottom\t 10.08984375\n",
    "- Left\t\t -54.597656250000014\n",
    "- Top\t\t 25.48828125\n",
    "- Right\t\t -31.535156250000014\n",
    "\n",
    "- Width\t\t 15.3984375\n",
    "- Height\t 23.0625\n",
    "\n",
    "### South Atlantic [1]\n",
    "\n",
    "\n",
    "- Bottom\t -21.48046875\n",
    "- Left\t\t -28.160156250000014\n",
    "- Top\t\t -6.08203125\n",
    "- Right\t\t -5.097656250000014\n",
    "- Width\t\t 15.3984375\n",
    "- Height\t 23.0625\n",
    "\n",
    "### East Pacific [2]\n",
    "\n",
    "\n",
    "- Bottom\t 9.66796875\n",
    "- Left\t\t 132.01171875\n",
    "- Top\t\t 25.06640625\n",
    "- Right\t\t 155.07421875\n",
    "- Width\t\t 15.3984375\n",
    "- Height\t 23.0625\n",
    "\n",
    "\n",
    "### South Pacific [3]\n",
    "\n",
    "\n",
    "- Bottom\t -20.63671875\n",
    "- Left\t\t -110.56640624999997\n",
    "- Top\t\t -5.23828125\n",
    "- Right\t\t -87.50390624999997\n",
    "- Width\t\t 15.3984375\n",
    "- Height\t 23.0625\n",
    "\n",
    "\n",
    "### South Pacific [3]\n",
    "\n",
    "- Bottom\t -20.49609375\n",
    "- Left\t\t -149.02734374999997\n",
    "- Top\t\t -5.09765625\n",
    "- Right\t\t -125.96484374999997\n",
    "- Width\t\t 15.3984375\n",
    "- Height\t 23.0625\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic = np.array([10.08984375, -54.597656250000014,  25.48828125, -31.535156250000014])\n",
    "south_atlantic = np.array([-21.48046875,  -28.160156250000014, -6.08203125, -5.097656250000014])\n",
    "east_paficific = np.array([9.66796875, 132.01171875, 25.06640625, 155.07421875])\n",
    "south_pacific_1 = np.array([-20.63671875, -110.56640624999997, -5.23828125, -87.50390624999997])\n",
    "south_pacific_2 = np.array([ -20.49609375, -149.02734374999997,  -5.09765625, -125.96484374999997])\n",
    "regions = np.array([atlantic, south_atlantic, east_paficific, south_pacific_1, south_pacific_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a list of all of the URLs we'll query. We keep them in tuple pairs of `(aquaUrl, terraUrl)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls():\n",
    "    \n",
    "    startDate = date(2012, 1, 1)\n",
    "    endDate   = date(2019, 7, 31)\n",
    "\n",
    "    allUrls = []\n",
    "\n",
    "    for dt in rrule(DAILY, dtstart=startDate, until=endDate):\n",
    "\n",
    "        current_date = dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        for bottom,left,top,right in regions:\n",
    "\n",
    "            aquaUrl = 'https://wvs.earthdata.nasa.gov/api/v1/snapshot?REQUEST=GetSnapshot&TIME={}T00:00:00Z&BBOX={},{},{},{}&CRS=EPSG:4326&LAYERS=MODIS_{}_CorrectedReflectance_TrueColor,Coastlines&WRAP=day,x&FORMAT=image/jpeg&WIDTH=525&HEIGHT=350&ts=1569875246328'.format(current_date, bottom, left, top, right, 'Aqua')\n",
    "            terraUrl = 'https://wvs.earthdata.nasa.gov/api/v1/snapshot?REQUEST=GetSnapshot&TIME={}T00:00:00Z&BBOX={},{},{},{}&CRS=EPSG:4326&LAYERS=MODIS_{}_CorrectedReflectance_TrueColor,Coastlines&WRAP=day,x&FORMAT=image/jpeg&WIDTH=525&HEIGHT=350&ts=1569875246328'.format(current_date, bottom, left, top, right, 'Terra')\n",
    "\n",
    "            allUrls.append((aquaUrl, terraUrl))\n",
    "            \n",
    "    return allUrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of urls: 13845\n",
      "Sample urls: https://wvs.earthdata.nasa.gov/api/v1/snapshot?REQUEST=GetSnapshot&TIME=2012-01-01T00:00:00Z&BBOX=-21.48046875,-28.160156250000014,-6.08203125,-5.097656250000014&CRS=EPSG:4326&LAYERS=MODIS_Aqua_CorrectedReflectance_TrueColor,Coastlines&WRAP=day,x&FORMAT=image/jpeg&WIDTH=525&HEIGHT=350&ts=1569875246328 \n",
      " https://wvs.earthdata.nasa.gov/api/v1/snapshot?REQUEST=GetSnapshot&TIME=2012-01-01T00:00:00Z&BBOX=-21.48046875,-28.160156250000014,-6.08203125,-5.097656250000014&CRS=EPSG:4326&LAYERS=MODIS_Terra_CorrectedReflectance_TrueColor,Coastlines&WRAP=day,x&FORMAT=image/jpeg&WIDTH=525&HEIGHT=350&ts=1569875246328\n"
     ]
    }
   ],
   "source": [
    "urls = getUrls()\n",
    "print(\"Number of urls:\", len(urls))\n",
    "print(\"Sample urls:\", urls[1][0], '\\n', urls[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImages(urlPair):\n",
    "    aquaUrl = urlPair[0]\n",
    "    terraUrl = urlPair[1]\n",
    "    aquaResponse = requests.get(aquaUrl)\n",
    "    terraResponse = requests.get(terraUrl)\n",
    "\n",
    "    aquaImg = Image.open(BytesIO(aquaResponse.content))\n",
    "    terraImg = Image.open(BytesIO(terraResponse.content))\n",
    "\n",
    "    name = ''.join(random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits) for _ in range(16))\n",
    "\n",
    "    aquaImg.save(\"data/aqua/\" + name + \".jpg\")\n",
    "    terraImg.save(\"data/terra/\" + name + \".jpg\")\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use eight threads to download them in parallel. This will take awhile.\n",
    "results = ThreadPool(8).imap_unordered(saveImages, urls)\n",
    "\n",
    "for path in results:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have about 13,000 pairs of similar images and we'd like to split them into train/valid sets. We'll set aside 1,000 pairs at random (ideally we'd probably set aside an equal number from each region, but I'm feeling lazy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = np.array(os.listdir(\"data/terra\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.arange(len(image_names))\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "train_indexes = indexes[1000:]\n",
    "valid_indexes = indexes[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_names = image_names[train_indexes]\n",
    "valid_image_names = image_names[valid_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_terra_paths = [\"data/terra/\" + s for s in train_image_names]\n",
    "train_aqua_paths = [\"data/aqua/\" + s for s in train_image_names]\n",
    "train_paths = train_terra_paths + train_aqua_paths\n",
    "train_labels = np.tile(train_image_names, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_terra_paths = [\"data/terra/\" + s for s in valid_image_names]\n",
    "valid_aqua_paths = [\"data/aqua/\" + s for s in valid_image_names]\n",
    "valid_paths = valid_terra_paths + valid_aqua_paths\n",
    "valid_labels = np.tile(valid_image_names, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/terra/FE41TSEI4Bzu63bF.jpg</td>\n",
       "      <td>FE41TSEI4Bzu63bF.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/terra/HhHfzOelzvw1bEBU.jpg</td>\n",
       "      <td>HhHfzOelzvw1bEBU.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/terra/wsEpaOq8jTJ7hYht.jpg</td>\n",
       "      <td>wsEpaOq8jTJ7hYht.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/terra/ZwFJhjN6Djvk8mgD.jpg</td>\n",
       "      <td>ZwFJhjN6Djvk8mgD.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/terra/HcEsYJanv3P5G1gY.jpg</td>\n",
       "      <td>HcEsYJanv3P5G1gY.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Path                 Label\n",
       "0  data/terra/FE41TSEI4Bzu63bF.jpg  FE41TSEI4Bzu63bF.jpg\n",
       "1  data/terra/HhHfzOelzvw1bEBU.jpg  HhHfzOelzvw1bEBU.jpg\n",
       "2  data/terra/wsEpaOq8jTJ7hYht.jpg  wsEpaOq8jTJ7hYht.jpg\n",
       "3  data/terra/ZwFJhjN6Djvk8mgD.jpg  ZwFJhjN6Djvk8mgD.jpg\n",
       "4  data/terra/HcEsYJanv3P5G1gY.jpg  HcEsYJanv3P5G1gY.jpg"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Path', 'Label']\n",
    "\n",
    "train = pd.DataFrame(zip(train_paths, train_labels), columns=cols)\n",
    "valid = pd.DataFrame(zip(valid_paths, valid_labels), columns=cols)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/image_similarity_train.csv\", index=False)\n",
    "valid.to_csv(\"data/image_similarity_valid.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
